{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [图像分类 | ILSVRC历届冠军网络[从AlexNet到SENet]](https://www.cnblogs.com/vincent1997/p/10901875.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前言\n",
    "\n",
    "+ 深度卷积网络极大地推进深度学习各领域的发展，ILSVRC作为最具影响力的竞赛功不可没，促使了许多金典工作。我梳理了ILSVRC分类任务的各界冠军和亚军网络，简单介绍了它们的核心思想、网络框架及其实现。  \n",
    "代码主要来自：[https://github.com/weiaicunzai/pytorch-cifar100](https://github.com/weiaicunzai/pytorch-cifar100)\n",
    "+ ImageNet和ILSVRC\n",
    "    + ImageNet是一个超过15 million的图像数据集，大约有22,000类。\n",
    "    + ILSVRC全称ImageNet Large-Scale Visual Recognition Challenge, 从2010年开始举办到2017年最后一届，使用ImageNet数据集的一个子集，总共有1000类。\n",
    "+ 历届结果\n",
    "\n",
    "![](./img/1.jpg)\n",
    "![](./img/2.png)\n",
    "\n",
    "ps: 上表和真实指标可能略有差距。\n",
    "+ 评价指标  \n",
    "    top1是指概率向量最大的作为预测结果，若分类正确，则为正确；top5则只要概率向量中最大的前五名里有分类正确的，则为正确。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet\n",
    "[Gradient-Based Learning Applied to Document Recognition](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)\n",
    "### 网络架构\n",
    "![](./img/6.png)\n",
    "\n",
    "+ 代码实现\n",
    "```python\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size = 5)\n",
    "        self.fc1 = nn.Linear(16 * 16,  120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = func.relu(self.conv1(x))\n",
    "        x = func.max_pool2d(x, 2)\n",
    "        x = func.relu(self.conv2(x))\n",
    "        x = func.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = func.relu(self.fc1(x))\n",
    "        x = func.relu(self.fc2(x))\n",
    "        x = func.fc3(x)\n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet\n",
    "[ImageNet Classification with Deep Convolutional Neural Networks](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)\n",
    "### 核心思想\n",
    "+ AlexNet相比前人有以下改进：\n",
    "    + 采用ReLU激活函数\n",
    "    + 局部响应归一化LRN\n",
    "    \n",
    "        ![](./img/3.png)\n",
    "    + Overlapping Pooling\n",
    "    + 引入Drop out\n",
    "    + 数据增强\n",
    "    + 多GPU并行\n",
    "    \n",
    "### 网络架构\n",
    "![](./img/4.png)\n",
    "+ 代码实现\n",
    "```python\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes = NUM_CLASSES):\n",
    "        super(AlexNet, self).__init()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size = 11, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(kernel_size = 2),\n",
    "            nn.Conv2d(96, 256, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(kernel_size = 2),\n",
    "            nn.Conv2d(256, 384, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(384, 384, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(384, 256, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(kernel_size = 2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 2 *2, 4096),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 256 * 2 * 2)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "```\n",
    "\n",
    "### 实验结果\n",
    "![](./img/5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZFNet\n",
    "[Visualizing and Understanding Convolutional Networks](https://arxiv.org/pdf/1311.2901.pdf)\n",
    "\n",
    "### 核心思想\n",
    "+ 利用反卷积可视化CNN学到的特征\n",
    "    + Unpooling: 池化操作不可逆，但通过记录池化最大值的位置可实现逆操作。\n",
    "    + Rectification: ReLU\n",
    "    + Fitering: 使用原卷积核的转置版本\n",
    "![](./img/7.png)\n",
    "\n",
    "### 网络架构\n",
    "![](./img/8.png)\n",
    "\n",
    "### 实验结果\n",
    "+ 特征可视化：Layer2响应角落和边缘、颜色连接；Layer3有更复杂的不变性，捕获相似纹理；Layer4展示了明显的变化，跟类别更相关；Layer5看到整个物体。\n",
    "\n",
    "![](./img/9.png)\n",
    "+ 训练过程特征演化：低层特征较快收敛，高层到后面才开始变化。上面每层从左到右训练次数为1，2，5，10，20，30，40，64个epoch。\n",
    "\n",
    "![](./img/10.png)\n",
    "+ 特征不变性：小变换在模型第一层变化明显，但在顶层影响较小。网络输出对翻转和缩放是稳定的，但除了旋转对称性的物体，输出对旋转并不是不变的。\n",
    "+ 遮挡敏感性： 当对象被遮挡，准确性会明显下降\n",
    "+ ImageNet结果\n",
    "\n",
    "![](./img/11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG\n",
    "[Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556v6)\n",
    "### 核心思想\n",
    "+ 重复使用3x3卷积和2x2池化增加网络深度。\n",
    "\n",
    "### 网络架构\n",
    "+ VGG19表示19层conv或fc,参数量较大。\n",
    "\n",
    "![](./img/12.png)\n",
    "\n",
    "### 代码实现\n",
    "\n",
    "```python\n",
    "cfg = {\n",
    "    'A' : [64,     'M', 128,      'M', 256, 256            'M', 512, 512,           'M', 512, 512,           'M'],\n",
    "    'B' : [64, 64, 'M', 128, 128, 'M', 256, 256,           'M', 512, 512,           'M', 512, 512,           'M'],\n",
    "    'D' : [64, 64, 'M', 128, 128, 'M', 256, 256, 256,      'M', 512, 512, 512,      'M', 512, 512, 512,      'M'],\n",
    "    'E' : [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "def vgg19_bn():\n",
    "    return VGG(make_layers(cfg['E'], batch_norm=True))\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, features, num_class = 100):\n",
    "        super().__init()\n",
    "        self.features = features \n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_class)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.features(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.classifier(output)\n",
    "        return output\n",
    "    \n",
    "    def make_layers(cfg, batch_norm=False):\n",
    "        layers = []\n",
    "        \n",
    "        input_channel = 3\n",
    "        for l in cfg:\n",
    "            if l == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size = 2, stride = 2)]\n",
    "                continue\n",
    "            \n",
    "            layers += [nn.Conv2d(input_channel, l, kernel_size = 3, padding = 1)]\n",
    "            \n",
    "            if batch_norm:\n",
    "                layers += [nn.BatchNorm2d(l)]\n",
    "            \n",
    "            layers += [nn.ReLU(inplace = True)]\n",
    "            input_channel = 1\n",
    "        return nn.Sequential(*layers)\n",
    "```\n",
    "\n",
    "### 实验结果\n",
    "\n",
    "![](./img/13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoogLeNet(V1)\n",
    "[Going Deeper with Convolutions](https://arxiv.org/abs/1409.4842v1)\n",
    "\n",
    "ps: [https://blog.csdn.net/weixin_39953502/article/details/80966046](https://blog.csdn.net/weixin_39953502/article/details/80966046)\n",
    "\n",
    "### 核心思想\n",
    "+ 提出Inception模块，可在保持计算成本的同时增加网络的深度和宽度。\n",
    "![](./img/14.png)\n",
    "\n",
    "### 代码实现\n",
    "```python\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, input_channels, n1x1, n3x3_reduce, n3x3, n5x5_reduce, n5x5, pool_proj):\n",
    "        super().__init__()\n",
    "        \n",
    "        #1x1conv branch\n",
    "        self.b1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, n1x1, kernel_size = 1),\n",
    "            nn.BatchNorm2d(n1x1),\n",
    "            nn.ReLU(inplace = True)\n",
    "        )\n",
    "        \n",
    "        #1x1conv -> 3x3conv branch\n",
    "        self.b2 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, n3x3_reduce, kernel_size = 1),\n",
    "            nn.BatchNorm2d(n3x3_reduce),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(n3x3_reduce, n3x3, kernel_size=3, padding = 1),\n",
    "            nn.BatchNorm2d(n3x3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # 1x1conv -> 5x5conv branch\n",
    "        # we use 2 3x3 conv filters stacked instead\n",
    "        # of 1 5x5filters to obtain the same receptive\n",
    "        # field with fewer parameters\n",
    "        self.b3 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, n5x5_reduce, kernel_size = 1),\n",
    "            nn.BatchNorm2d(n5x5_reduce),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(n5x5_reduce, n5x5, kernel_size = 3, padding = 1),\n",
    "            nn.BatchNorm2d(n5x5, n5x5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(n5x5, n5x5, kernel_size = 3, padding = 1),\n",
    "            nn.BatchNorm2d(n5x5),\n",
    "            nn.ReLU(inplace = True)\n",
    "        )\n",
    "        \n",
    "        # 3x3pooling ->1x1conv\n",
    "        # same conv\n",
    "        self.b4 = nn.Sequential(\n",
    "            nn.MaxPool2d(3, stride = 1, padding = 1),\n",
    "            nn.Conv2d(input_channels, pool_proj, kernel_size = 1),\n",
    "            nn.BatchNorm2d(pool_proj),\n",
    "            nn.ReLU(inplace = True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.b1(x), self.b2(x), self.b3(x), self.b4(x)], dim = 1)\n",
    "```\n",
    "\n",
    "### 网络架构\n",
    "> 高清图看论文\n",
    "\n",
    "![](./img/15.png)\n",
    "![](./img/16.png)\n",
    "\n",
    "### 代码实现\n",
    "```python\n",
    "def googlenet():\n",
    "    return GoogleNet()\n",
    "\n",
    "class GoogleNet(nn.Module):\n",
    "    def __init__(self, num_class=100):\n",
    "        super().__init__()\n",
    "        self.prelayer = nn.Sequential(\n",
    "            nn.Conv2d(3, 192, kernel_size = 3, padding = 1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(inplace = True)\n",
    "        )\n",
    "        \n",
    "        # although we only use 1 conv layer as prelayer,\n",
    "        # we stil use name a3, b3...\n",
    "        self.a3 = Inception(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.b3 = Inception(256, 128, 192, 32, 96, 64)\n",
    "        \n",
    "        # In general, an Inception network is a network consisting of\n",
    "        # modules of the above type stacked upon each other, with occasional\n",
    "        # max-pooling layers with stride 2 to halve the resolution of the grid\n",
    "        self.maxpool = nn.MaxPool2d(3, stride=2, padding = 1)\n",
    "        \n",
    "        self.a4 = Inception(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.b4 = Inception(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.c4 = Inception(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.d4 = Inception(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.e4 = Inception(528, 256, 160, 320, 32, 128, 128)\n",
    "        \n",
    "        self.a5 = Inception(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.b5 = Inception(832, 384, 192, 284, 48, 128, 128)\n",
    "        \n",
    "        # input feature size: 8*8*1024\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.dropout = nn.Dropout2d(p=0.4)\n",
    "        self.linear = nn.Linear(1024, num_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.prelayer(x)\n",
    "        output = self.a3(output)\n",
    "        output = self.b3(output)\n",
    "        \n",
    "        output = self.maxpool(output)\n",
    "        \n",
    "        output = self.a5(output)\n",
    "        output = self.b5(output)\n",
    "        \n",
    "        # It was found that a move from fully connected layers \n",
    "        # to average pooling imporved the top-1 accuracy by about 0.6%,\n",
    "        # however the use of dorpout remained essential even after\n",
    "        # removing the fully connected layers.\n",
    "        output = self.avgpool(output)\n",
    "        output = self.dropout(output)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.linear(output)\n",
    "        \n",
    "        return output\n",
    "```\n",
    "### 实验结果\n",
    "![](./img/17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet\n",
    "[Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385v1)\n",
    "\n",
    "### 核心思想\n",
    "+ 为了解决深层网络难以训练的问题，提出了残差模块和深度残差网络\n",
    "    + 假设网络输入是x，经学习的输出是F(x),最终拟合的目标是H(x)。\n",
    "    + 深层网络相比浅层网络有一些层是多余的，若让多余层学习恒等变换H(x)=x，那么网络性能不该比浅层网络要差。\n",
    "    + 传统网络训练目标H(x)= F(x), 残差网络训练目标H(x)=F(x) + x\n",
    "    + 为了学习恒等变换，传统网络要求网络学习F(x) = H(x) = x， 残差网络只需学习F(x) = H(x)-x = x-x = 0. 残差学习之所以有效是因为让网络学习F(x) = 0比学习F(x)=x要容易。\n",
    "\n",
    "![](./img/18.png)\n",
    "\n",
    "+ bottleneck\n",
    "\n",
    "![](./img/19.jpg)\n",
    "\n",
    "+ 代码实现\n",
    "``` python\n",
    "class BottleNeck(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual block for resnet over 50 layers\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, stride = 1):\n",
    "        super().__init__()\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size= 1, bias = False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, stride = stride, kernel_size=3, padding = 1, bias = False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels*BottleNeck.expansion, kernel_size = 1, bias= False),\n",
    "            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n",
    "        )\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        \n",
    "        if stride != 1 or inchannels != out_channels * BottleNeck.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, stride = stride, kernel_size = 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels*BottleNeck.expansion)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        return nn.ReLU(inplace = True)(self.residul_function(x) + self.shortcut(x))\n",
    "```\n",
    "\n",
    "### 网络架构\n",
    "![](./img/19.png)\n",
    "![](./img/20.png)\n",
    "\n",
    "### 代码实现\n",
    "```python\n",
    "def resnet152():\n",
    "    '''return a ResNet 152 object\n",
    "    '''\n",
    "    return ResNet(BottleNeck, [3, 8, 36, 3])\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_block, num_classes = 100):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_channels = 64\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.COnv2d(3, 64, kernel_size = 3, padding = 1, bias = False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace = True)\n",
    "        )\n",
    "        #we use a different inputsize than the original paper\n",
    "        # so conv2_x's stride is 1\n",
    "        self.conv2_x = self._make_layer(block, 64, num_block(0), 1)\n",
    "        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
    "        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
    "        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, * block.expansion, num_classed)\n",
    "        \n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        \"\"\"make resnet layers(by layer i didnt mean this 'layer' was the \n",
    "        same as a neuron netowork layer, ex. conv layer), one layer may \n",
    "        contain more than one residual block \n",
    "\n",
    "        Args:\n",
    "            block: block type, basic block or bottle neck block\n",
    "            out_channels: output depth channel number of this layer\n",
    "            num_blocks: how many blocks per layer\n",
    "            stride: the stride of the first block of this layer\n",
    "        \n",
    "        Return:\n",
    "            return a resnet layer\n",
    "        \"\"\"\n",
    "        \n",
    "        # we have num_block blocks per layer, the first block \n",
    "        # could be 1 or 2, other blocks would always be 1\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2_x(output)\n",
    "        output = self.conv3_x(output)\n",
    "        output = self.conv4_x(output)\n",
    "        output = self.conv5_x(output)\n",
    "        output = self.avg_pool(output)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output \n",
    "```\n",
    "\n",
    "### 实验结果\n",
    "\n",
    "![](./img/21.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNext\n",
    "\n",
    "[Aggregated Residual Transformations for Deep Neural Networks](https://arxiv.org/pdf/1611.05431.pdf)\n",
    "\n",
    "### 核心思想\n",
    "+ 通过重复构建block来聚合一组相同拓扑结构的特征，并提出一个新维度\"cardinality\"。\n",
    "+ resNext结合了VGG, ResNet重复堆叠模块和Inception的split-transform-merge的思想。\n",
    "\n",
    "![](./img/22.png)\n",
    "\n",
    "以下三者等价，文章采用第三种实现，其使用了组卷积\n",
    "![](./img/23.png)\n",
    "\n",
    "+ 代码实现\n",
    "\n",
    "```python\n",
    "CARDINALITY = 32\n",
    "DEPTH = 4\n",
    "BASEWIDTH = 64\n",
    "\n",
    "class ResNextBottleNeckC(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super().__init__()\n",
    "\n",
    "        C = CARDINALITY #How many groups a feature map was splitted into\n",
    "\n",
    "        #\"\"\"We note that the input/output width of the template is fixed as \n",
    "        #256-d (Fig. 3), We note that the input/output width of the template \n",
    "        #is fixed as 256-d (Fig. 3), and all widths are dou- bled each time \n",
    "        #when the feature map is subsampled (see Table 1).\"\"\"\n",
    "        D = int(DEPTH * out_channels / BASEWIDTH) #number of channels per group\n",
    "        self.split_transforms = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, C * D, kernel_size=1, groups=C, bias=False),\n",
    "            nn.BatchNorm2d(C * D),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(C * D, C * D, kernel_size=3, stride=stride, groups=C, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(C * D),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(C * D, out_channels * 4, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * 4),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels * 4:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * 4, stride=stride, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * 4)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu(self.split_transforms(x) + self.shortcut(x))\n",
    "```\n",
    "\n",
    "\n",
    "### 网络架构\n",
    "![](./img/24.png)\n",
    "\n",
    "+ 代码实现\n",
    "  以下部分跟ResNet基本一致，重点关注ResnextBottleNeckC的实现\n",
    "  \n",
    "\n",
    "```python\n",
    "def resnext50():\n",
    "    \"\"\" return a resnext50(c32x4d) network\n",
    "    \"\"\"\n",
    "    return ResNext(ResNextBottleNeckC, [3, 4, 6, 3])\n",
    "\n",
    "class ResNext(nn.Module):\n",
    "    def __init__(self, block, num_blocks, class_names=100):\n",
    "        super().__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv2 = self._make_layer(block, num_blocks[0], 64, 1)\n",
    "        self.conv3 = self._make_layer(block, num_blocks[1], 128, 2)\n",
    "        self.conv4 = self._make_layer(block, num_blocks[2], 256, 2)\n",
    "        self.conv5 = self._make_layer(block, num_blocks[3], 512, 2)\n",
    "        self.avg = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * 4, 100)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.avg(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def _make_layer(self, block, num_block, out_channels, stride):\n",
    "        \"\"\"Building resnext block\n",
    "        Args:\n",
    "            block: block type(default resnext bottleneck c)\n",
    "            num_block: number of blocks per layer\n",
    "            out_channels: output channels per block\n",
    "            stride: block stride\n",
    "        \n",
    "        Returns:\n",
    "            a resnext layer\n",
    "        \"\"\"\n",
    "        strides = [stride] + [1] * (num_block - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * 4\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "```\n",
    "\n",
    "### 实验结果\n",
    "\n",
    "![](./img/25.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SENet\n",
    "[Squeeze-and-Excitation Networks](https://arxiv.org/abs/1709.01507)\n",
    "\n",
    "### 核心思想\n",
    "+ 卷积操作融合了空间和特征通道信息。大量工作研究了空间部分，而本文重点关注特征通道的关系，并提出了Squeeze-and-Excitation(SE)block，对通道间的依赖关系进行建模，自适应校准通道方面的特征响应。\n",
    "\n",
    "+ SE block\n",
    "    Ftr表示transformation（一系列卷积操作）；Fsq表示squeeze，产生通道描述；Fex表示excitation，通过参数W来建模通道的重要性。Fscale表示reweight，将excitation输出的权重逐乘以先前特征，完成特征重标定。\n",
    "    \n",
    "![](./img/26.png)\n",
    "\n",
    "\n",
    "+ SE-ResNet Module\n",
    "\n",
    "![](./img/27.png)\n",
    "\n",
    "+ 代码实现\n",
    "\n",
    "```python\n",
    "class BottleneckResidualSEBlock(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride, r=16):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(out_channels, out_channels, 3, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(out_channels, out_channels * self.expansion, 1),\n",
    "            nn.BatchNorm2d(out_channels * self.expansion),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d(1)\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(out_channels * self.expansion, out_channels * self.expansion // r),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(out_channels * self.expansion // r, out_channels * self.expansion),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels * self.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * self.expansion, 1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels * self.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        shortcut = self.shortcut(x)\n",
    "\n",
    "        residual = self.residual(x)\n",
    "        squeeze = self.squeeze(residual)\n",
    "        squeeze = squeeze.view(squeeze.size(0), -1)\n",
    "        excitation = self.excitation(squeeze)\n",
    "        excitation = excitation.view(residual.size(0), residual.size(1), 1, 1)\n",
    "\n",
    "        x = residual * excitation.expand_as(residual) + shortcut\n",
    "\n",
    "        return F.relu(x)\n",
    "```\n",
    "\n",
    "### 网络架构\n",
    "\n",
    "![](./img/28.png)\n",
    "\n",
    "+ 代码实现\n",
    "\n",
    "```python \n",
    "def seresnet50():\n",
    "    return SEResNet(BottleneckResidualSEBlock, [3, 4, 6, 3])\n",
    "\n",
    "class SEResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, block_num, class_num=100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.pre = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.stage1 = self._make_stage(block, block_num[0], 64, 1)\n",
    "        self.stage2 = self._make_stage(block, block_num[1], 128, 2)\n",
    "        self.stage3 = self._make_stage(block, block_num[2], 256, 2)\n",
    "        self.stage4 = self._make_stage(block, block_num[3], 516, 2)\n",
    "\n",
    "        self.linear = nn.Linear(self.in_channels, class_num)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pre(x)\n",
    "\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "\n",
    "        x = F.adaptive_avg_pool2d(x, 1)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def _make_stage(self, block, num, out_channels, stride):\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        while num - 1:\n",
    "            layers.append(block(self.in_channels, out_channels, 1))\n",
    "            num -= 1\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "```\n",
    "\n",
    "+ 实验结果\n",
    "\n",
    "![](./img/29.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "+ 小结\n",
    "    1. LeNet[1998]：CNN的鼻祖。\n",
    "    2. AlexNet[2012]：第一个深度CNN。\n",
    "    3. ZFNet[2012]：通过DeconvNet可视化CNN学习到的特征。\n",
    "    4. VGG[2014]：重复堆叠3x3卷积增加网络深度。\n",
    "    5. GoogLeNet[2014]：提出Inception模块，在控制参数和计算量的前提下，增加网络的深度与宽度。\n",
    "    6. ResNet[2015]：提出残差网络，解决了深层网络的优化问题。\n",
    "    7. ResNeXt[2016]：ResNet和Inception的结合体，Inception中每个分支结构相同，无需人为设计。\n",
    "    8. SENet[2017]：提出SE block，关注特征的通道关系。\n",
    "\n",
    "+ 经典模型结构中、参数对比\n",
    "\n",
    "![](./img/30.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
