{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO V1\n",
    "### 参考\n",
    "1.[目标检测——搭建更好更快的YOLO！](https://zhuanlan.zhihu.com/p/94589951)  \n",
    "2.[You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.02640)\n",
    "\n",
    "# 模型框架\n",
    "## 1. 论文模型框架\n",
    "![](./img/yolo_v1_row.PNG)\n",
    "### 1.1 Backbone\n",
    "使用ResNet作为backbone\n",
    "![](./img/ResNet-18.jpg)\n",
    "### 1.2 Head\n",
    "SPP+SAM\n",
    "#### 1.2.1 SPP\n",
    "![](./img/SPP.jpg)\n",
    "#### 1.2.2 SAM\n",
    "![](./img/SAM.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码实现\n",
    "## 1. Backbone(ResNet)\n",
    "### 1.1 残差原理\n",
    "![](./img/Residual_Block.PNG)\n",
    "### 1.2 ResNet 基本结构\n",
    "![](./img/ResNet_Architectures.PNG)\n",
    "### 1.3 BasicBlock and Bottleneck\n",
    "![](./img/ResNet_basic_block.PNG)\n",
    "### 1.4 实现思路\n",
    "1. 通过形如resnet\\*()(\\*代指18，50，101，152等)的函数返回ressnet实例\n",
    "2. _resnet()具体实例化以及加载模型参数，返回实例化后的参数\n",
    "3. 定义ResNet主体框架\n",
    "4. 定义BasicBlock以及Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "\n",
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152']\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes: int, out_planes: int, stride: int=1)->nn.Conv2d:\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                    padding=1, bias=False)\n",
    "\n",
    "def conv1x1(in_planes: int, out_planes: int, stride: int=1)->nn.Conv2d:\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
    "                    bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion: int = 1\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        inplanes: int, \n",
    "        planes: int, \n",
    "        stride: int=1, \n",
    "        downsample: Optional[nn.Module]=None\n",
    "    ) -> None:\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "        \n",
    "class Bottleneck(nn.Module):\n",
    "    expansion: int = 4\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int=1,\n",
    "        downsample: Optional[nn.Module] = None\n",
    "    ) -> None:\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = conv1x1(inplanes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes, stride)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = conv1x1(planes, planes)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Type[Union[BasicBlock, Bottleneck]],\n",
    "        layers: List[int],\n",
    "        zero_init_residual: bool=False\n",
    "    ) -> None:\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3,\n",
    "                              bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.layer1 = self._make_layer(block, 64,  layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride = 2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride = 2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride = 2)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "        \n",
    "    def _make_layer(\n",
    "        self, \n",
    "        block: Type[Union[BasicBlock, Bottleneck]], \n",
    "        planes: int, \n",
    "        blocks: int, \n",
    "        stride: int=1\n",
    "    ) -> nn.Sequential:\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "            \n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \n",
    "        C_1 = self.conv1(x)\n",
    "        C_1 = self.bn1(C_1)\n",
    "        C_1 = self.relu(C_1)\n",
    "        C_1 = self.maxpool(C_1)\n",
    "        \n",
    "        C_2 = self.layer1(C_1)\n",
    "        C_3 = self.layer2(C_2)\n",
    "        C_4 = self.layer3(C_3)\n",
    "        C_5 = self.layer4(C_4)\n",
    "        \n",
    "        return C_3, C_4, C_5\n",
    "    \n",
    "\n",
    "def resnet18(pretrained: bool=False, hr_pretrained: bool=False, **kwargs: Any)->ResNet:\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        # strict = False as we don't need fc layer params.\n",
    "        if hr_pretrained:\n",
    "            print('Loading the high resolution pretrained model ...')\n",
    "            model.load_state_dict(torch.load(\"backbone/weights/resnet18_hr_10.pth\"), strict=False)\n",
    "        else:\n",
    "            model.load_state_dict(model_zoo.load_url(model_urls['resnet18']), strict=False)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(pretrained: bool=False, hr_pretrained: bool=False, **kwargs: Any)->ResNet:\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']), strict=False)\n",
    "    return model\n",
    "\n",
    "def resnet50(pretrained: bool=False, hr_pretrained: bool=False, **kwargs: Any)->ResNet:\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']), strict=False)\n",
    "    return model\n",
    "\n",
    "def resnet101(pretrained: bool=False, hr_pretrained: bool=False, **kwargs: Any)->ResNet:\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']), strict=False)\n",
    "    return model\n",
    "\n",
    "def resnet152(pretrained: bool=False, hr_pretrained: bool=False, **kwargs: Any)->ResNet:\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
    "    return model\n",
    "\n",
    "# if __name__=='__main__':\n",
    "#     #model = torchvision.models.resnet50()\n",
    "#     print(\"found \", torch.cuda.device_count(), \" GPU(s)\")\n",
    "#     device = torch.device(\"cuda\")\n",
    "#     model = resnet18(pretrained=True)#.to(device)\n",
    "#     print(model)\n",
    "\n",
    "#     input_data = torch.randn(1, 3, 512, 512)#.to(device)\n",
    "#     output = model(input_data)\n",
    "#     print(output[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Head(SPP + SAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "\n",
    "class Conv2d(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int,\n",
    "        padding: int=0,\n",
    "        stride: int=0,\n",
    "        dilation: int=1,\n",
    "        leakyReLU: bool=False\n",
    "    )->None:\n",
    "        super(Conv2d, self).__init__()\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.1, inplace=True) if leakyReLU else nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: Tensor)->Tensor:\n",
    "        return self.convs(x)\n",
    "    \n",
    "class SAM(nn.Module):\n",
    "    \"\"\"Parallel CBAM\"\"\"\n",
    "    def __init__(self, in_channels: int) ->None:\n",
    "        super(SAM, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: Tensor)->Tensor:\n",
    "        \"\"\" Spatial Attention Module \"\"\"\n",
    "        x_attention = self.conv(x)\n",
    "\n",
    "        return x * x_attention\n",
    "        \n",
    "class SPP(nn.Module):\n",
    "    \"\"\"\n",
    "        Spatial Pyramid Pooling\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int)->None:\n",
    "        super(SPP, self).__init__()\n",
    "        self.fuse_conv = Conv2d(in_channels * 4, out_channels, 1, leakyReLU=True)\n",
    "\n",
    "    def forward(self, x: Tensor)-> Tensor:\n",
    "        x_1 = F.max_pool2d(x, 5, stride=1, padding=2)\n",
    "        x_2 = F.max_pool2d(x, 9, stride=1, padding=4)\n",
    "        x_3 = F.max_pool2d(x, 13, stride=1, padding=6)\n",
    "        x = torch.cat([x, x_1, x_2, x_3], dim=1)\n",
    "\n",
    "        return self.fuse_conv(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BCELoss(nn.Module):\n",
    "    def __init__(self,  weight=None, ignore_index=-100, reduce=None, reduction='mean'):\n",
    "        super(BCELoss, self).__init__()\n",
    "        self.reduction = reduction\n",
    "    def forward(self, inputs, targets):\n",
    "        pos_id = (targets==1.0).float()\n",
    "        neg_id = (targets==0.0).float()\n",
    "        pos_loss = -pos_id * torch.log(inputs + 1e-14)\n",
    "        neg_loss = -neg_id * torch.log(1.0 - inputs + 1e-14)\n",
    "        if self.reduction == 'mean':\n",
    "            pos_loss = torch.mean(torch.sum(pos_loss, 1))\n",
    "            neg_loss = torch.mean(torch.sum(neg_loss, 1))\n",
    "            return pos_loss, neg_loss\n",
    "        else:\n",
    "            return pos_loss, neg_loss\n",
    "\n",
    "\n",
    "class MSELoss(nn.Module):\n",
    "    def __init__(self, reduction='mean'):\n",
    "        super(MSELoss, self).__init__()\n",
    "        self.reduction = reduction\n",
    "    def forward(self, inputs, targets):\n",
    "        pos_id = (targets==1.0).float()\n",
    "        neg_id = (targets==0.0).float()\n",
    "        pos_loss = pos_id * (inputs - targets)**2\n",
    "        neg_loss = neg_id * (inputs)**2\n",
    "        if self.reduction == 'mean':\n",
    "            pos_loss = torch.mean(torch.sum(pos_loss, 1))\n",
    "            neg_loss = torch.mean(torch.sum(neg_loss, 1))\n",
    "            return pos_loss, neg_loss\n",
    "        else:\n",
    "            return pos_loss, neg_loss\n",
    "\n",
    "\n",
    "class BCE_focal_loss(nn.Module):\n",
    "    def __init__(self,  weight=None, gamma=2, reduction='mean'):\n",
    "        super(BCE_focal_loss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    def forward(self, inputs, targets):\n",
    "        pos_id = (targets==1.0).float()\n",
    "        neg_id = (1 - pos_id).float()\n",
    "        pos_loss = -pos_id * (1.0-inputs)**self.gamma * torch.log(inputs + 1e-14)\n",
    "        neg_loss = -neg_id * (inputs)**self.gamma * torch.log(1.0 - inputs + 1e-14)\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(torch.sum(pos_loss+neg_loss, 1))\n",
    "        else:\n",
    "            return pos_loss+neg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dxdywh(gt_label, w, h, s):\n",
    "    xmin, ymin, xmax, ymax = gt_label[:-1]\n",
    "    # compute the center, width and height\n",
    "    c_x = (xmax + xmin) / 2 * w\n",
    "    c_y = (ymax + ymin) / 2 * h\n",
    "    box_w = (xmax - xmin) * w\n",
    "    box_h = (ymax - ymin) * h\n",
    "\n",
    "    if box_w < 1e-28 or box_h < 1e-28:\n",
    "        # print('A dirty data !!!')\n",
    "        return False    \n",
    "\n",
    "    # map center point of box to the grid cell\n",
    "    c_x_s = c_x / s\n",
    "    c_y_s = c_y / s\n",
    "    grid_x = int(c_x_s)\n",
    "    grid_y = int(c_y_s)\n",
    "    # compute the (x, y, w, h) for the corresponding grid cell\n",
    "    tx = c_x_s - grid_x\n",
    "    ty = c_y_s - grid_y\n",
    "    tw = np.log(box_w)\n",
    "    th = np.log(box_h)\n",
    "    weight = 2.0 - (box_w / w) * (box_h / h)\n",
    "\n",
    "    return grid_x, grid_y, tx, ty, tw, th, weight\n",
    "\n",
    "\n",
    "def gt_creator(input_size, stride, label_lists=[], name='VOC'):\n",
    "    assert len(input_size) > 0 and len(label_lists) > 0\n",
    "    # prepare the all empty gt datas\n",
    "    batch_size = len(label_lists)\n",
    "    w = input_size[1]\n",
    "    h = input_size[0]\n",
    "    \n",
    "    # We  make gt labels by anchor-free method and anchor-based method.\n",
    "    ws = w // stride\n",
    "    hs = h // stride\n",
    "    s = stride\n",
    "    gt_tensor = np.zeros([batch_size, hs, ws, 1+1+4+1])\n",
    "\n",
    "    # generate gt whose style is yolo-v1\n",
    "    for batch_index in range(batch_size):\n",
    "        for gt_label in label_lists[batch_index]:\n",
    "            gt_class = int(gt_label[-1])\n",
    "            result = generate_dxdywh(gt_label, w, h, s)\n",
    "            if result:\n",
    "                grid_x, grid_y, tx, ty, tw, th, weight = result\n",
    "\n",
    "                if grid_x < gt_tensor.shape[2] and grid_y < gt_tensor.shape[1]:\n",
    "                    gt_tensor[batch_index, grid_y, grid_x, 0] = 1.0\n",
    "                    gt_tensor[batch_index, grid_y, grid_x, 1] = gt_class\n",
    "                    gt_tensor[batch_index, grid_y, grid_x, 2:6] = np.array([tx, ty, tw, th])\n",
    "                    gt_tensor[batch_index, grid_y, grid_x, 6] = weight\n",
    "\n",
    "\n",
    "    gt_tensor = gt_tensor.reshape(batch_size, -1, 1+1+4+1)\n",
    "\n",
    "    return gt_tensor\n",
    "\n",
    "\n",
    "def loss(pred_conf, pred_cls, pred_txtytwth, label):\n",
    "    obj = 5.0\n",
    "    noobj = 1.0\n",
    "\n",
    "    # create loss_f\n",
    "    conf_loss_function = MSELoss(reduction='mean')\n",
    "    cls_loss_function = nn.CrossEntropyLoss(reduction='none')\n",
    "    txty_loss_function = nn.BCEWithLogitsLoss(reduction='none')\n",
    "    twth_loss_function = nn.MSELoss(reduction='none')\n",
    "\n",
    "    pred_conf = torch.sigmoid(pred_conf[:, :, 0])\n",
    "    pred_cls = pred_cls.permute(0, 2, 1)\n",
    "    pred_txty = pred_txtytwth[:, :, :2]\n",
    "    pred_twth = pred_txtytwth[:, :, 2:]\n",
    "        \n",
    "    gt_obj = label[:, :, 0].float()\n",
    "    gt_cls = label[:, :, 1].long()\n",
    "    gt_txtytwth = label[:, :, 2:-1].float()\n",
    "    gt_box_scale_weight = label[:, :, -1]\n",
    "\n",
    "    # objectness loss\n",
    "    pos_loss, neg_loss = conf_loss_function(pred_conf, gt_obj)\n",
    "    conf_loss = obj * pos_loss + noobj * neg_loss\n",
    "    \n",
    "    # class loss\n",
    "    cls_loss = torch.mean(torch.sum(cls_loss_function(pred_cls, gt_cls) * gt_obj, 1))\n",
    "    \n",
    "    # box loss\n",
    "    txty_loss = torch.mean(torch.sum(torch.sum(txty_loss_function(pred_txty, gt_txtytwth[:, :, :2]), 2) * gt_box_scale_weight * gt_obj, 1))\n",
    "    twth_loss = torch.mean(torch.sum(torch.sum(twth_loss_function(pred_twth, gt_txtytwth[:, :, 2:]), 2) * gt_box_scale_weight * gt_obj, 1))\n",
    "\n",
    "    txtytwth_loss = txty_loss + twth_loss\n",
    "\n",
    "    total_loss = conf_loss + cls_loss + txtytwth_loss\n",
    "\n",
    "    return conf_loss, cls_loss, txtytwth_loss, total_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. YOLO_V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "\n",
    "class CustomYOLO(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        device: torch.device,\n",
    "        input_size: int,\n",
    "        num_classes: int=20,\n",
    "        trainable: bool=False,\n",
    "        conf_thresh: float=0.01, \n",
    "        nms_thresh: float=0.5,\n",
    "    ) -> None:\n",
    "        super(CustomYOLO, self).__init__()\n",
    "        self.device = device\n",
    "        self.num_classes = num_classes\n",
    "        self.trainable = trainable\n",
    "        self.conf_thresh = conf_thresh\n",
    "        self.nms_thresh = nms_thresh\n",
    "        self.stride = 32\n",
    "        self.grid_cell = self.create_grid(input_size)\n",
    "        self.input_size = input_size\n",
    "        self.scale = np.array([[input_size[1], input_size[0], input_size[1], input_size[0]]])\n",
    "        self.scale_torch = torch.tensor(self.scale.copy(), device=device).float()\n",
    "        \n",
    "        # we use resnet18 as backbone\n",
    "        self.backbone = resnet18(pretrained=True)\n",
    "        self.SPP = SPP(512, 512)\n",
    "        self.SAM = SAM(512)\n",
    "        self.conv_set = nn.Sequential(\n",
    "            Conv2d(512, 256, 1, leakyReLU=True),\n",
    "            Conv2d(256, 512, 3, padding=1, leakyReLU=True),\n",
    "            Conv2d(512, 256, 1, leakyReLU=True),\n",
    "            Conv2d(256, 512, 3, padding=1, leakyReLU=True),\n",
    "        )\n",
    "\n",
    "        self.pred = nn.Conv2d(512, 1 + self.num_classes + 4, 1)\n",
    "        \n",
    "    def create_grid(self, input_size: int)->Tensor:\n",
    "        w, h = input_size[1], input_size[0]\n",
    "        # generate grid cells\n",
    "        ws, hs = w // self.stride, h // self.stride\n",
    "        grid_y, grid_x = torch.meshgrid([torch.arange(hs), torch.arange(ws)])\n",
    "        grid_xy = torch.stack([grid_x, grid_y], dim=-1).float()\n",
    "        grid_xy = grid_xy.view(1, hs*ws, 2).to(self.device)\n",
    "        \n",
    "        return grid_xy\n",
    "    \n",
    "    def set_grid(self, input_size: int)->None:\n",
    "        self.input_size = input_size\n",
    "        self.grid_cell = self.create_grid(input_size)\n",
    "        self.scale = np.array([[[input_size[1], input_size[0], input_size[1], input_size[0]]]])\n",
    "        self.scale_torch = torch.tensor(self.scale.copy(), device=self.device).float()\n",
    "        \n",
    "    def decode_boxes(self, pred: Tensor)-> Tensor:\n",
    "        \"\"\"\n",
    "        input box :  [tx, ty, tw, th]\n",
    "        output box : [xmin, ymin, xmax, ymax]\n",
    "        \"\"\"\n",
    "        output = torch.zeros_like(pred)\n",
    "        pred[:, :, :2] = torch.sigmoid(pred[:, :, :2]) + self.grid_cell\n",
    "        pred[:, :, 2:] = torch.exp(pred[:, :, 2:])\n",
    "        \n",
    "        # [c_x, c_y, w, h] -> [xmin, ymin, xmax, ymax]\n",
    "        output[:, :, 0] = pred[:, :, 0] * self.stride - pred[:, :, 2] / 2\n",
    "        output[:, :, 1] = pred[:, :, 1] * self.stride - pred[:, :, 3] / 2\n",
    "        output[:, :, 2] = pred[:, :, 0] * self.stride + pred[:, :, 2] / 2\n",
    "        output[:, :, 3] = pred[:, :, 1] * self.stride + pred[:, :, 3] / 2\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def nms(self, dets: Tensor, scores: Tensor)-> List:\n",
    "        x1, y1, x2, y2 = dets[:, 0], dets[:, 1], dets[:, 2], dets[:, 3]  # xmin, ymin, xmax, ymax\n",
    "        \n",
    "        areas = (x2-x1)*(y2-y1)            # the size of bbox\n",
    "        order = scores.argsort()[::-1]     # sort bounding boxes by decreasing order\n",
    "        \n",
    "        keep = []                                             # store the final bounding boxes\n",
    "        while order.size > 0:\n",
    "            i = order[0]                                      #the index of the bbox with highest confidence\n",
    "            keep.append(i)                                    #save it to keep\n",
    "            xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "            yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "            xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "            yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "            w = np.maximum(1e-28, xx2 - xx1)\n",
    "            h = np.maximum(1e-28, yy2 - yy1)\n",
    "            inter = w * h\n",
    "\n",
    "            # Cross Area / (bbox + particular area - Cross Area)\n",
    "            ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "            #reserve all the boundingbox whose ovr less than thresh\n",
    "            inds = np.where(ovr <= self.nms_thresh)[0]\n",
    "            order = order[inds + 1]\n",
    "\n",
    "        return keep       \n",
    "        \n",
    "        \n",
    "    def postprocess(self, all_local, all_conf, exchange=True, im_shape=None):\n",
    "        \"\"\"\n",
    "        bbox_pred: (HxW, 4), bsize = 1\n",
    "        prob_pred: (HxW, num_classes), bsize = 1\n",
    "        \"\"\"\n",
    "        bbox_pred = all_local\n",
    "        prob_pred = all_conf\n",
    "\n",
    "        cls_inds = np.argmax(prob_pred, axis=1)\n",
    "        prob_pred = prob_pred[(np.arange(prob_pred.shape[0]), cls_inds)]\n",
    "        scores = prob_pred.copy()\n",
    "        \n",
    "        # threshold\n",
    "        keep = np.where(scores >= self.conf_thresh)\n",
    "        bbox_pred = bbox_pred[keep]\n",
    "        scores = scores[keep]\n",
    "        cls_inds = cls_inds[keep]\n",
    "\n",
    "        # NMS\n",
    "        keep = np.zeros(len(bbox_pred), dtype=np.int)\n",
    "        for i in range(self.num_classes):\n",
    "            inds = np.where(cls_inds == i)[0]\n",
    "            if len(inds) == 0:\n",
    "                continue\n",
    "            c_bboxes = bbox_pred[inds]\n",
    "            c_scores = scores[inds]\n",
    "            c_keep = self.nms(c_bboxes, c_scores)\n",
    "            keep[inds[c_keep]] = 1\n",
    "\n",
    "        keep = np.where(keep > 0)\n",
    "        bbox_pred = bbox_pred[keep]\n",
    "        scores = scores[keep]\n",
    "        cls_inds = cls_inds[keep]\n",
    "\n",
    "        if im_shape != None:\n",
    "            # clip\n",
    "            bbox_pred = self.clip_boxes(bbox_pred, im_shape)\n",
    "\n",
    "        return bbox_pred, scores, cls_inds\n",
    "\n",
    "    \n",
    "    def forward(self, x, target=None):\n",
    "        # backbone\n",
    "        _, _, C_5 = self.backbone(x)\n",
    "\n",
    "        # head\n",
    "        C_5 = self.SPP(C_5)\n",
    "        C_5 = self.SAM(C_5)\n",
    "        C_5 = self.conv_set(C_5)\n",
    "\n",
    "        # pred\n",
    "        prediction = self.pred(C_5)\n",
    "        prediction = prediction.view(C_5.size(0), 1 + self.num_classes + 4, -1).permute(0, 2, 1)\n",
    "        B, HW, C = prediction.size()\n",
    "\n",
    "        # Divide prediction to obj_pred, txtytwth_pred and cls_pred   \n",
    "        # [B, H*W, 1]\n",
    "        conf_pred = prediction[:, :, :1]\n",
    "        # [B, H*W, num_cls]\n",
    "        cls_pred = prediction[:, :, 1 : 1 + self.num_classes]\n",
    "        # [B, H*W, 4]\n",
    "        txtytwth_pred = prediction[:, :, 1 + self.num_classes:]\n",
    "        if not self.trainable:\n",
    "            with torch.no_grad():\n",
    "                # batch size = 1\n",
    "                all_conf = torch.sigmoid(conf_pred)[0]           # 0 is because that these is only 1 batch.\n",
    "                all_bbox = torch.clamp((self.decode_boxes(txtytwth_pred) / self.scale_torch)[0], 0., 1.)\n",
    "                all_class = (torch.softmax(cls_pred[0, :, :], 1) * all_conf)\n",
    "                \n",
    "                # separate box pred and class conf\n",
    "                all_conf = all_conf.to('cpu').numpy()\n",
    "                all_class = all_class.to('cpu').numpy()\n",
    "                all_bbox = all_bbox.to('cpu').numpy()\n",
    "                \n",
    "                bboxes, scores, cls_inds = self.postprocess(all_bbox, all_class)\n",
    "\n",
    "                return bboxes, scores, cls_inds\n",
    "        else:\n",
    "            conf_loss, cls_loss, txtytwth_loss, total_loss = loss(pred_conf=conf_pred, pred_cls=cls_pred,\n",
    "                                                                        pred_txtytwth=txtytwth_pred,\n",
    "                                                                        label=target)\n",
    "\n",
    "            return conf_loss, cls_loss, txtytwth_loss, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found  0  GPU(s)\n",
      "CustomYOLO(\n",
      "  (backbone): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (SPP): SPP(\n",
      "    (fuse_conv): Conv2d(\n",
      "      (convs): Sequential(\n",
      "        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(0, 0))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (SAM): SAM(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (conv_set): Sequential(\n",
      "    (0): Conv2d(\n",
      "      (convs): Sequential(\n",
      "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(0, 0))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Conv2d(\n",
      "      (convs): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(0, 0), padding=(1, 1))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Conv2d(\n",
      "      (convs): Sequential(\n",
      "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(0, 0))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Conv2d(\n",
      "      (convs): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(0, 0), padding=(1, 1))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pred): Conv2d(512, 25, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "non-positive stride is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-2da9effa369c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0minput_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#.to(device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Develop\\Anaconda3\\envs\\lls_pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-e4f53ed05605>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, target)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;31m# head\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mC_5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSPP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC_5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[0mC_5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSAM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC_5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[0mC_5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC_5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Develop\\Anaconda3\\envs\\lls_pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-29d9eb10f8ea>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfuse_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Develop\\Anaconda3\\envs\\lls_pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-29d9eb10f8ea>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m->\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mSAM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Develop\\Anaconda3\\envs\\lls_pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Develop\\Anaconda3\\envs\\lls_pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Develop\\Anaconda3\\envs\\lls_pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Develop\\Anaconda3\\envs\\lls_pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Develop\\Anaconda3\\envs\\lls_pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 342\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: non-positive stride is not supported"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    #model = torchvision.models.resnet50()\n",
    "    print(\"found \", torch.cuda.device_count(), \" GPU(s)\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    model = CustomYOLO(device, input_size=[512, 512], num_classes=20, trainable=False)\n",
    "    print(model)\n",
    "\n",
    "    input_data = torch.randn(1, 3, 512, 512)#.to(device)\n",
    "    output = model(input_data)\n",
    "    print(output[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
